#!/usr/bin/env python
# encoding: utf-8
'''
@author: MiaFeng
@contact: skaudrey@163.com
@file: buildData.py
@time: 2018/10/8 7:46
@desc:
'''
import pandas as pd
from util.io_util import readCSV,saveAsCSV
from util.path_util import getPath
from util.io_util import save_model,load_model,makeFileDescription
from sklearn.preprocessing import StandardScaler

band_idx = ['51532','51533','51534','51546','51547','51548','51553','51554','51555','51894','51895']
sea_cols = ['ch921','ch386','ch306','ch241','label','band_idx']
# typ_train_cols =
chan_four = [921,386,306,241]

def scaleTrain(df,chan_num,topo,category):
    scaler = StandardScaler().fit(df)
    df = scaler.transform(df)
    scaler_name = save_model('%s_%s_%d'%(topo,category,chan_num),scaler,modelName='scaler')
    return df

def scaleTest(df_test,chan_num,topo,category):
    scaler = load_model('%s_%s_%d'%(topo,category,chan_num),modelName='scaler')
    df_test = scaler.transform(df_test)
    return df_test

def getFeatureCols(chan_num,isRaw = True, isAddEmiss = False):
    '''
    get columns names, isRaw denotes whether the data will be used for model, otherwise all useful features will be kept.
    :param category:
    :param chan_num:
    :param isRaw:
    :return:
    '''
    cols = []
    if isRaw:
        cols = ['lon', 'lat']
    cols += getChanIndex('chan_%d'%chan_num)
    cols += ['label']
    if isAddEmiss: # 加入地表发射率
        cols += getEmisIndex()
    if isRaw:
        cols += ['band_idx']
    return cols


def defineIASISpectIntervalIndex(chanIndexList):
    chanIntervalIASIIndex = [
        [21, 580],
        [581, 2140],
        [2261, 4021],
        [5821, 6020],
        [6021, 6421],
        [6821, 7101],
        [7101, 8221]
    ]
    chanIndex_return = [-1]*len(chanIndexList)
    for chanIdx, chanIndex in enumerate(chanIndexList):
        for idx, chanInter in enumerate(chanIntervalIASIIndex):
            if ((chanIndex >= chanInter[0]) and (chanIndex <= chanInter[1])):
                chanIndex_return[chanIdx] = idx
    return chanIndex_return

def tagChan616(chanIndexList):
    chanIntervalLabels = ['temp_cold_cloud',
                          'surface and cloud,ozone',
                          'water, temperature profile, nitrous oxide, methane and sulfur dioxide detection',
                          'carbon dioxide',
                          'the amount of nitrous oxide detection',
                          'temperature profile detection',
                          'surface and cloud characteristics']
    chanIntervalSpect = [[650,790],
                         [790,1180],
                         [1210,1650],
                         [2100,2150],
                         [2150,2250],
                         [2350,2420],
                         [2420,2700]]

    chanIntervalIASIIndex = [
        [21,580],
        [581,2140],
        [2261,4021],
        [5821,6020],
        [6021,6421],
        [6821,7101],
        [7101,8221]
    ]

    chanIntervalIndices = list(range(len(chanIntervalLabels)))

    chanIndex_tag = defineIASISpectIntervalIndex(chanIndexList)

    chanIndexIASIInfo = {
        'chanIntervalLabels':chanIntervalLabels,
        'chanIntervalSpect': chanIntervalSpect,
        'chanIntervalIASIIndex': chanIntervalIASIIndex,
    }

    saveDataAsPKL('IASI_chan_map_detect_type_info',chanIndexIASIInfo,category = 'data')

    df_chan = pd.DataFrame({
        'chanIndex': chanIndexList,
        'tag': chanIndex_tag
    })


    df_chan.to_csv('%s/IASI_chan_map_detect_type.csv'%(getPath('data')))




def getChanIndex(chanType='chan_4'):
    chanIndex = []
    if chanType == 'chan_4':
        chanIndex = chan_four
    elif chanType == 'chan_616':
        chanIndex = pd.read_table('%s/%s'%(getPath('data'),'chan_index.dat'),header=None)
        chanIndex = chanIndex[0].values.tolist()
    elif chanType == 'num':
        chanIndex = pd.read_table('%s/%s' % (getPath('data'), 'chan_index.dat'), header=None)
        chanIndex = chanIndex[0].values.tolist()
        return chanIndex
    cols = list(map(lambda x:'ch%d'%x,chanIndex))
    return cols

def getEmisIndex():
    return list(map(lambda x:'emis_%d'%x,list(range(1,13))))

def getRawColsNames(category = 'chan_4'):
    '''
    used for assigning features' column names while loading the raw data.
    :param category:
    :return:
    '''
    cols = ['lon','lat']
    cols += getChanIndex(category)
    cols += ['cloud_fraction']
    cols += getEmisIndex()
    cols = cols + ['topo','band_idx']
    return cols

def getBandIndices(typName):
    '''
    raw data generated by matlab code is saved according to band indices
    :param typName:
    :return:
    '''
    if typName=='catfish':
        return band_idx[:-2]
    elif typName=='seahorse':
        return band_idx[-2:]

def gatherTypDataAsCSV(typName,category = 'typ',chan_num=4):
    '''
    combine the data saved in each band into the whole file
    :param typName:
    :param category:
    :return:
    '''
    indices = getBandIndices(typName)
    df = pd.DataFrame()
    for band_idx in indices:
        df_tmp = readCSV('%s_%d_%s'%(category,chan_num,band_idx),category=category,fileType='txt')
        print(df_tmp.shape)
        df_tmp = pd.concat([df_tmp,pd.DataFrame({'band_idx':[band_idx]*len(df_tmp)})],axis=1)
        df = pd.concat([df,df_tmp],ignore_index=True)

    df.columns = getRawColsNames('chan_%d'%chan_num)
    cols = getRawColsNames('chan_%d'%chan_num)

    df['cloud_fraction'][df['cloud_fraction']==-1] = 0
    print(len(df))
    assert (sum(df.cloud_fraction < 0))==0
    filename = 'raw_%s_%d'%(typName,chan_num)
    saveAsCSV(df,filename,category=category,header=cols)

def cleanData(typName,chan_num,topo = 'sea',category = 'typ',cloud_fraction_thresh=80):
    '''
    drop data where cloud_fraction < threshold and surface emissivity is missed if topo=='land'
    :param typName:
    :param category:
    :return:
    '''
    df = readCSV('%s_%d'%(typName,chan_num),category=category,header='infer')
    # filter the cloudy and clear field
    df = df[(df.cloud_fraction==0) | (df.cloud_fraction>=cloud_fraction_thresh)]
    # drop points missing channels' data
    cols_chan = getChanIndex('chan_%d'%chan_num)
    df_chan_index = df[cols_chan][df[cols_chan]<0].dropna()
    df_chan_index = df_chan_index.index.tolist()
    df = df.dropna()
    df = df.drop(df_chan_index)
    df.reset_index(drop=True,inplace=True)
    # assert sum(sum((df[cols_chan]<0).values)) == 0

    print('data size of cloud fraction picked --> %d' % len(df))

    if topo=='land':
        df = df[df>=0].dropna()
        print('data size of cloud fraction and surface emissivity defined --> %d' % len(df))
    typName = typName.split('_')[1]

    print(80*'-')
    print('size of cloudy point (cloud_fraction >= %d) --> %d'% (cloud_fraction_thresh,len(df[df['cloud_fraction']>=cloud_fraction_thresh])))
    print('size of clear point (cloud_fraction = 0) --> %d' % len(df[df['cloud_fraction'] == 0]))

    print(80*'-')

    print('size of water topo point (topo==0) --> %d' % len(df[df['topo'] == 0]))
    print('size of land topo point (topo==1 | topo == 2) --> %d' % len(df[(df['topo'] == 1) | (df['topo'] == 2)]))
    print('size of mixed topo point (topo==3 | topo == 4) --> %d' % len(df[(df.topo == 3)|(df.topo == 4)]))

    cols = getRawColsNames('chan_%d'%chan_num)

    saveAsCSV(df,'%s_%d'%(typName,chan_num),category=category,header=cols)

def getTopoData(df,topoType='sea'):
    if topoType == 'sea': # water
        df = df[df['topo']==0]
    elif topoType == 'land': # land low, land high
        df = df[(df['topo']==1) | (df['topo']==2) ]
        df = df[df >= 0].dropna()
    elif topoType == 'mix': # land water low, land water high
        df = df[(df['topo'] == 3) | (df['topo'] == 4)]
        df = df[df >= 0].dropna()

    return df

def tagData(df,cloud_fraction_thresh=80):
    df['label'] = 1
    df['label'][df['cloud_fraction'] == 0] = 0
    return df

def buildTypData(trainTyp,testTyp,chan_num,rescale = False):
    '''
    Fields are taken as cloudy when cloud_fraction is bigger than cloud_fraction_thresh
    :param trainTyp:
    :param testTyp:
    :param cloud_fraction_thresh:
    :return:
    '''
    category = 'typ'
    df_train = readCSV('%s_%d'%(trainTyp,chan_num),category=category,header='infer')
    df_test = readCSV('%s_%d'%(testTyp,chan_num),category=category,header='infer')
    df_train = tagData(df_train)
    df_test = tagData(df_test)

    # -----------  split by topology  ------------
    # sea
    df_train_sea = getTopoData(df_train,'sea')
    df_test_sea = getTopoData(df_test,'sea')

    # land
    df_train_land = getTopoData(df_train,'land')
    df_test_land = getTopoData(df_test,'land')

    # -----------  extract features  ------------
    # -----------  extract sea features  ------------
    feaCols = getFeatureCols(chan_num,isAddEmiss=False,isRaw=True)
    df_train_sea = df_train_sea[feaCols]
    df_test_sea = df_test_sea[feaCols]
    if rescale:
        feaCols_tmp = getChanIndex('chan_%d'%chan_num)
        df_train_sea[feaCols_tmp] = scaleTrain(df_train_sea[feaCols_tmp],chan_num,topo='sea',category=category)
        df_test_sea[feaCols_tmp] = scaleTest(df_test_sea[feaCols_tmp],chan_num=chan_num,topo='sea',category=category)
    print('sea data set size --> train: %d, test: %d' % (len(df_train_sea),len(df_test_sea)))
    print('training cloud point size / clear point size --> %d / %d'%(len(df_train_sea[df_train_sea['label']==1]),
                                                                      len(df_train_sea[df_train_sea['label']==0])))
    print('test cloud point size / clear point size --> %d / %d' % (len(df_test_sea[df_test_sea['label'] == 1]),
                                                                        len(df_test_sea[df_test_sea['label'] == 0])))
    feaCols = getFeatureCols(chan_num, isAddEmiss=True,isRaw=True)
    df_train_land = df_train_land[feaCols]
    df_test_land = df_test_land[feaCols]
    if rescale:
        feaCols_tmp = getChanIndex('chan_%d'%chan_num)+getEmisIndex()
        df_train_land[feaCols_tmp] = scaleTrain(df_train_land[feaCols_tmp],chan_num,topo='land',category=category)
        df_test_land[feaCols_tmp] = scaleTest(df_test_land[feaCols_tmp],chan_num=chan_num,topo='land',category=category)
    print('land data set size --> train: %d, test: %d' % (len(df_train_land), len(df_test_land)))
    print('training cloud point size / clear point size --> %d / %d' % (len(df_train_land[df_train_land['label'] == 1]),
                                                                        len(df_train_land[df_train_land['label'] == 0])))
    print('test cloud point size / clear point size --> %d / %d' % (len(df_test_land[df_test_land['label'] == 1]),
                                                                    len(df_test_land[df_test_land['label'] == 0])))
    fileName = makeFileDescription('sea', category, chan_num, trainTyp, rescale, isTrain=True)
    saveAsCSV(df_train_sea,fileName=fileName,category=category,header='infer')
    fileName = makeFileDescription('sea', category, chan_num, testTyp, rescale, isTrain=False)
    saveAsCSV(df_test_sea, fileName=fileName, category=category, header='infer')
    fileName = makeFileDescription('land', category, chan_num, trainTyp, rescale, isTrain=True)
    saveAsCSV(df_train_land, fileName=fileName, category=category, header='infer')
    fileName = makeFileDescription('land', category, chan_num, testTyp, rescale, isTrain=False)
    saveAsCSV(df_test_land, fileName=fileName, category=category, header='infer')

def buildAllData(trainTyp,testTyp, chan_num,topo='land',data_category='',rescale=False):
    '''
    processing all the data and split to sea and land topo
    :param trainTyp:
    :param testTyp:
    :param chan_num:
    :param rescale:
    :return:
    '''
    category = 'all'
    df_train,df_test = pd.DataFrame(),pd.DataFrame()
    if len(data_category)>0 and data_category=='raw':
        df_train = readCSV('raw_%s_%d' % (trainTyp, chan_num), category='all', header='infer')
        df_test = readCSV('raw_%s_%d' % (testTyp, chan_num), category='all', header='infer')

    else:
        df_train = readCSV('%s_%d' % (trainTyp, chan_num), category='all', header='infer')
        df_test = readCSV('%s_%d' % (testTyp, chan_num), category='all', header='infer')
    df_train = getTopoData(df_train, topo)
    df_test = getTopoData(df_test, topo)
    df_train = tagData(df_train)
    df_test = tagData(df_test)
    feaCols = getFeatureCols(chan_num,isAddEmiss=True,isRaw=True)
    df_train_land = df_train[feaCols]
    df_test_land = df_test[feaCols]
    print('land data set size --> train: %d, test: %d' % (len(df_train_land), len(df_test_land)))
    print('training cloud point size / clear point size --> %d / %d' % (len(df_train_land[df_train_land['label'] == 1]),
                                                                        len(df_train_land[
                                                                                df_train_land['label'] == 0])))
    print('test cloud point size / clear point size --> %d / %d' % (len(df_test_land[df_test_land['label'] == 1]),
                                                                    len(df_test_land[df_test_land['label'] == 0])))

    if rescale:
        feaCols_tmp = getChanIndex('chan_%d'%chan_num)+getEmisIndex()
        df_train_land[feaCols_tmp] = scaleTrain(df_train_land[feaCols_tmp],chan_num,'land',category=category)
        df_test_land[feaCols_tmp] = scaleTest(df_test_land[feaCols_tmp],chan_num,'land',category=category)

    fileName = makeFileDescription(topo,category,chan_num,trainTyp,rescale,isTrain=True)
    saveAsCSV(df_train_land, fileName, category=category, header='infer')
    fileName = makeFileDescription(topo, category, chan_num, testTyp, rescale, isTrain=False)
    saveAsCSV(df_test_land, fileName=fileName, category=category, header='infer')


def clean51895():
    chan_num = 51894
    df = readCSV('%s_%d' % ('typ', chan_num), category='data', fileType='txt')
    chan_num = 51895
    df_tmp = readCSV('%s_%d' % ('typ', chan_num), category='data', fileType='txt')

    df = pd.concat([df,df_tmp])

    a = ['lon', 'lat','ch921','ch386','ch306','ch241', 'label', 'emis_1', 'emis_2', 'emis_3', 'emis_4', 'emis_5', 'emis_6', 'emis_7', 'emis_8', 'emis_9', 'emis_10', 'emis_11', 'emis_12', 'topo']
    df.columns = a
    # filter the cloudy and clear field
    df = df[['lon', 'lat','ch921','ch386','ch306','ch241', 'label', 'topo']]
    df = df[(df.label == 0) | (df.label >= 80)]
    df['cloud_flag'] = [1] * len(df)
    df['cloud_flag'][df['label']==0] = 0
    # drop points missing channels' data
    # cols_chan = getChanIndex('chan_%d' % chan_num)
    # df_chan_index = df[cols_chan][df[cols_chan] < 0].dropna()
    # df_chan_index = df_chan_index.index.tolist()
    # df = df.dropna()
    # df = df.drop(df_chan_index)
    # df.reset_index(drop=True, inplace=True)
    # assert sum(sum((df[cols_chan]<0).values)) == 0
    df['topo_flag'] = df['topo']
    df[['lon','lat','cloud_flag','topo_flag']].to_csv('%s/cloud_true.csv' % getPath('data'), encoding='utf-8', index=None)


if __name__=='__main__':
    # # gather data
    # category = 'all'
    # gatherTypDataAsCSV('catfish',category)
    # gatherTypDataAsCSV('seahorse',category)
    # category = 'typ'
    # gatherTypDataAsCSV('catfish', category)
    # gatherTypDataAsCSV('seahorse', category)
    # gatherTypDataAsCSV('catfish', category,chan_num=616)
    # gatherTypDataAsCSV('seahorse', category,chan_num=616)
    # clean data
    # category,chan_num = 'all',4
    # topo = 'sea', category = 'typ', cloud_fraction_thresh = 80):
    # cleanData('raw_seahorse',chan_num,topo='land',category)
    # cleanData('raw_catfish', chan_num,topo='land',category)
    # category = 'typ'
    # cleanData('raw_seahorse', chan_num, category=category)
    # cleanData('raw_catfish', chan_num, category=category)
    # chan_num = 616
    # cleanData('raw_seahorse', chan_num, category=category)
    # cleanData('raw_catfish', chan_num, category=category)
    # buildTypData('catfish','seahorse',4)
    # buildTypData('catfish','seahorse',616)
    # buildLandData('catfish','seahorse',4)
    # buildTypData('catfish', 'seahorse', 4, rescale=True)
    # buildTypData('catfish', 'seahorse', 616, rescale=True)
    # buildLandData('catfish', 'seahorse', 4, rescale=True)
    # buildAllData('catfish', 'seahorse', 4, topo='sea',data_category='raw',rescale=True)

    from util.io_util import loadDataFromPKL,saveDataAsPKL


    # t1 = loadDataFromPKL('sea_typ_4_tuning_grid_scores')

    # t2 = load_model('sea_typ_4','xgbc')

    # clean51895()
    chanList = getChanIndex('num')
    tagChan616(chanList)

    print('c')
